"""
Exemple d'utilisation du modÃ¨le entraÃ®nÃ© pour faire des prÃ©dictions
"""
import os
import sys
import argparse
import numpy as np
import cv2
from pathlib import Path

import config
from visualize import predict_and_visualize, extract_keypoints_from_heatmaps


def predict_on_image(model_path, image_path, output_path=None):
    """
    Fait une prÃ©diction sur une seule image
    
    Args:
        model_path: Chemin vers le modÃ¨le .h5
        image_path: Chemin vers l'image
        output_path: Chemin pour sauvegarder la visualisation (optionnel)
    """
    from tensorflow import keras
    
    print("=" * 60)
    print("ğŸ”® PRÃ‰DICTION SUR UNE IMAGE")
    print("=" * 60)
    
    # Charger le modÃ¨le
    print(f"\nğŸ“‚ Chargement du modÃ¨le: {model_path}")
    model = keras.models.load_model(model_path)
    print("âœ… ModÃ¨le chargÃ©")
    
    # Faire la prÃ©diction et visualiser
    print(f"\nğŸ“· PrÃ©diction sur: {image_path}")
    heatmaps, keypoints = predict_and_visualize(model, image_path, save_path=output_path)
    
    # Afficher les rÃ©sultats
    print("\nğŸ“Š RÃ©sultats:")
    print(f"   - Heatmaps shape: {heatmaps.shape}")
    print(f"   - Keypoints dÃ©tectÃ©s: {len(keypoints)}")
    
    return heatmaps, keypoints


def predict_on_folder(model_path, folder_path, output_dir=None, max_images=None):
    """
    Fait des prÃ©dictions sur toutes les images d'un dossier
    
    Args:
        model_path: Chemin vers le modÃ¨le .h5
        folder_path: Dossier contenant les images
        output_dir: Dossier pour sauvegarder les visualisations
        max_images: Nombre maximum d'images Ã  traiter (None = toutes)
    """
    from tensorflow import keras
    
    print("=" * 60)
    print("ğŸ”® PRÃ‰DICTION SUR UN DOSSIER")
    print("=" * 60)
    
    # Charger le modÃ¨le
    print(f"\nğŸ“‚ Chargement du modÃ¨le: {model_path}")
    model = keras.models.load_model(model_path)
    print("âœ… ModÃ¨le chargÃ©")
    
    # CrÃ©er le dossier de sortie
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s dans: {output_dir}")
    
    # Lister les images
    folder = Path(folder_path)
    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp']
    images = [f for f in folder.iterdir() 
              if f.suffix.lower() in image_extensions]
    
    if max_images:
        images = images[:max_images]
    
    print(f"\nğŸ“· {len(images)} images trouvÃ©es")
    
    # PrÃ©dire sur chaque image
    all_keypoints = []
    
    for i, image_path in enumerate(images):
        print(f"\n[{i+1}/{len(images)}] Traitement: {image_path.name}")
        
        save_path = None
        if output_dir:
            save_path = os.path.join(output_dir, f"pred_{image_path.stem}.png")
        
        heatmaps, keypoints = predict_and_visualize(
            model, str(image_path), save_path=save_path
        )
        
        all_keypoints.append({
            'image': image_path.name,
            'keypoints': keypoints
        })
    
    # Sauvegarder les rÃ©sultats dans un fichier
    if output_dir:
        results_file = os.path.join(output_dir, "predictions.txt")
        with open(results_file, 'w') as f:
            f.write("IMAGE,BODYPART,X,Y\n")
            for result in all_keypoints:
                for i, bodypart in enumerate(config.BODYPARTS):
                    x, y = result['keypoints'][i]
                    f.write(f"{result['image']},{bodypart},{x:.4f},{y:.4f}\n")
        
        print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s: {results_file}")
    
    print("\nâœ… Traitement terminÃ©!")
    return all_keypoints


def predict_with_tflite(tflite_path, image_path):
    """
    Fait une prÃ©diction avec le modÃ¨le TFLite
    
    Args:
        tflite_path: Chemin vers le modÃ¨le .tflite
        image_path: Chemin vers l'image
    """
    import tensorflow as tf
    
    print("=" * 60)
    print("ğŸ”® PRÃ‰DICTION AVEC TFLITE")
    print("=" * 60)
    
    # Charger l'interprÃ©teur
    print(f"\nğŸ“‚ Chargement du modÃ¨le TFLite: {tflite_path}")
    interpreter = tf.lite.Interpreter(model_path=tflite_path)
    interpreter.allocate_tensors()
    
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"âœ… ModÃ¨le chargÃ©")
    print(f"   - Input shape: {input_details[0]['shape']}")
    print(f"   - Output shape: {output_details[0]['shape']}")
    
    # Charger et prÃ©traiter l'image
    print(f"\nğŸ“· Chargement de l'image: {image_path}")
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, config.IMAGE_SIZE)
    img = img.astype(np.float32) / 255.0
    
    # PrÃ©parer l'entrÃ©e
    input_data = np.expand_dims(img, axis=0).astype(np.float32)
    
    # Si quantization, convertir en uint8
    if input_details[0]['dtype'] == np.uint8:
        input_scale, input_zero_point = input_details[0]['quantization']
        input_data = (input_data / input_scale + input_zero_point).astype(np.uint8)
    
    # InfÃ©rence
    print("\nğŸ”„ InfÃ©rence en cours...")
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()
    
    # RÃ©cupÃ©rer la sortie
    output_data = interpreter.get_tensor(output_details[0]['index'])
    
    # Si quantization, dÃ©quantizer
    if output_details[0]['dtype'] == np.uint8:
        output_scale, output_zero_point = output_details[0]['quantization']
        output_data = (output_data.astype(np.float32) - output_zero_point) * output_scale
    
    heatmaps = output_data[0]
    
    # Extraire les keypoints
    keypoints = extract_keypoints_from_heatmaps(heatmaps)
    
    print("\nâœ… PrÃ©diction terminÃ©e!")
    print(f"\nğŸ“ Keypoints dÃ©tectÃ©s:")
    for i, bodypart in enumerate(config.BODYPARTS):
        print(f"   {bodypart}: x={keypoints[i][0]:.3f}, y={keypoints[i][1]:.3f}")
    
    return heatmaps, keypoints


def main():
    parser = argparse.ArgumentParser(description="PrÃ©dictions avec le modÃ¨le entraÃ®nÃ©")
    
    parser.add_argument(
        '--model',
        type=str,
        default=None,
        help="Chemin vers le modÃ¨le .h5 ou .tflite"
    )
    parser.add_argument(
        '--image',
        type=str,
        default=None,
        help="Chemin vers une image"
    )
    parser.add_argument(
        '--folder',
        type=str,
        default=None,
        help="Chemin vers un dossier d'images"
    )
    parser.add_argument(
        '--output',
        type=str,
        default='output/predictions',
        help="Dossier de sortie pour les visualisations"
    )
    parser.add_argument(
        '--max-images',
        type=int,
        default=None,
        help="Nombre max d'images Ã  traiter (dossier)"
    )
    parser.add_argument(
        '--tflite',
        action='store_true',
        help="Utiliser le modÃ¨le TFLite au lieu de .h5"
    )
    
    args = parser.parse_args()
    
    # VÃ©rifier les arguments
    if not args.model:
        # Chercher le dernier modÃ¨le dans tous les dossiers de modÃ¨les
        output_dir = Path(config.OUTPUT_DIR)
        models = []
        
        # Parcourir tous les dossiers de modÃ¨les
        for model_dir in output_dir.iterdir():
            if model_dir.is_dir() and not model_dir.name.startswith('.'):
                models_subdir = model_dir / "models"
                if models_subdir.exists():
                    if args.tflite:
                        models.extend(list(models_subdir.glob("*.tflite")))
                    else:
                        models.extend(list(models_subdir.glob("*_best.h5")))
        
        if models:
            args.model = str(max(models, key=os.path.getctime))
            print(f"ğŸ’¡ Utilisation du modÃ¨le: {args.model}")
        else:
            print("âŒ Aucun modÃ¨le trouvÃ©!")
            print("ğŸ’¡ SpÃ©cifiez un modÃ¨le avec --model")
            return
    
    if not args.image and not args.folder:
        print("âŒ Vous devez spÃ©cifier --image ou --folder")
        return
    
    # Faire les prÃ©dictions
    try:
        # DÃ©terminer le dossier de sortie basÃ© sur le modÃ¨le actuel
        model_path = Path(args.model)
        model_dir = model_path.parent.parent  # Remonter de models/ vers le dossier du modÃ¨le
        default_output_dir = model_dir / "predictions"
        
        if args.tflite:
            if args.image:
                predict_with_tflite(args.model, args.image)
            else:
                print("âŒ --tflite supporte seulement --image pour le moment")
        else:
            if args.image:
                predict_on_image(args.model, args.image, output_path=str(default_output_dir / "prediction_single.png"))
            elif args.folder:
                predict_on_folder(args.model, args.folder, str(default_output_dir), args.max_images)
    
    except Exception as e:
        print(f"\nâŒ Erreur: {e}")
        raise


if __name__ == "__main__":
    main()
